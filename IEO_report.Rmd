```{r setup, cache = FALSE, echo = FALSE, results = 'asis'}
library("knitr")
dumpcssfile <- function(fname) {
  paste(c('<style type = "text/css">', readLines(fname), '</style>\n'),
        collapse = "\n")
}

opts_chunk$set(cache = TRUE,
               autodep = TRUE,
               fig.align = "center",
               comment = "",
               tidy = TRUE,
               message = FALSE,
               source = function(x, options) {
    paste("\\begin{lstlisting}[numbers=left, firstnumber=last]\n", x, 
        "\\end{lstlisting}\n", sep = "")
}) 
# Some modifications from http://stackoverflow.com/a/27633734/2886003

knit_hooks$set(error = function(x, options) stop(x),
               fig.cap = function(before, options, envir) {
                 if (!before) {
                   paste0('<p class = "caption">', options$fig.cap, "</p>")
                 }
               })

# Modifications based on https://rpubs.com/ajlyons/autonumfigs
# A function for generating captions and cross-references
fig <- local({
    i <- 0
    list(
        cap=function(refName, text, center=FALSE, col="black", inline=FALSE) {
            i <<- i + 1
            ref[[refName]] <<- i
            css_ctr <- ""
            if (center) css_ctr <- "text-align:center; display:inline-block; width:100%;"
            cap_txt <- paste0("<span style=\"color:", col, "; ", css_ctr, "\">Figure ", i, ": ", text , "</span>")
            anchor <- paste0("<a name=\"", refName, "\"></a>")
            if (inline) {
                paste0(anchor, cap_txt)    
            } else {
                list(anchor=anchor, cap_txt=cap_txt)
            }
        },
        
        ref=function(refName, link=FALSE, checkRef=TRUE) {
            
            ## This function puts in a cross reference to a caption. You refer to the
            ## caption with the refName that was passed to fig$cap() (not the code chunk name).
            ## The cross reference can be hyperlinked.
            
            if (checkRef && !refName %in% names(ref)) stop(paste0("fig$ref() error: ", refName, " not found"))
            if (link) {
                paste0("<A HREF=\"#", refName, "\">Figure ", ref[[refName]], "</A>")
            } else {
                paste0("Figure ", ref[[refName]])
            }
        },
        
        ref_all=function(){
            ## For debugging
            ref
        })
})

## This chunk replaces the default hook for processing plots. It achieves the purposes,
## of laying out auto-numbered captions, but other functionality may be gone.
knit_hooks$set(plot = function(x, options) {
    sty <- ""
    if (options$fig.align == 'default') {
        sty <- ""
    } else {
        sty <- paste0(" style=\"text-align:", options$fig.align, ";\"")
    }
    
    if (is.list(options$fig.cap)) {
        ## options$fig.cap is a list returned by the function fig$cap()
        str_caption <- options$fig.cap$cap_txt
        str_anchr <- options$fig.cap$anchor
    } else {
        ## options$fig.cap is a character object (hard coded, no anchor)
        str_caption <- options$fig.cap
        str_anchr <- ""
    }
    
    paste('<figure', sty, '>', str_anchr, '<img src="',
        opts_knit$get('base.url'), paste(x, collapse = '.'),
        '"><figcaption>', str_caption, '</figcaption></figure>',
        sep = '')
    
})

## This chunck will read through *this* Rmd file, and attempt to extract all of the 
## labels (not caption text) used for Figure captions. These labels are used
## as anchors, so scanning through the document now will allow us to create cross references
## before the caption actually appears. 

## Get the name of this Rmd file
rmdFn <- knitr::current_input()  # filename of input document

## Read lines and close connection
rmdCon <- file(rmdFn, open = "r")
rmdLines <- readLines(rmdCon)
close(rmdCon)

## Pull out all occurences of at least one back tick, followed 
## by any number of characters, followed by fig$cap (all on one line)
figscap_idx <- grep("`+(.*)fig\\$cap", rmdLines)
rmdLines <- rmdLines[figscap_idx]

## Get rid of everything up until the start of the caption label
## This presumes the caption label is the first argument of fig$cap()
## E.g., fig.cap = fig$cap("my_label", ...)
rmdLinesSansPre <- sub("(.*)fig\\$cap(.*?)[\"']", "", rmdLines)

## Identify everything up until the first quote
match_data <- regexpr("(.*?)[\"']", rmdLinesSansPre)

## Reduce the length by one, because we're not interested in the final quote
attr(match_data, "match.length") <- attr(match_data, "match.length") - 1

## Extract
fig_labels <- regmatches(rmdLinesSansPre, match_data, invert=FALSE)

if (length(fig_labels) > 0) {

    ## Test for duplicates
    if (anyDuplicated(fig_labels) > 0) stop("Duplicate caption labels detected")
    
    ## Create a named list of Figure numbers
    ref <- as.list(1:length(fig_labels))
    names(ref) <- fig_labels
}    

cat(dumpcssfile(file.path("css", "ieo.css")))
```
---
output: html_document
---
# Analysis of a TCGA RNA-seq data set on Thyroid carcinoma (THCA)

#### Mauro Álvarez (mail)
#### Lluís Revilla(lluis.revilla01@estudiant.upf.edu)
#### Marina Reixachs (marina.reixachs01@estudiant.upf.edu)
#### Inés Sentís (mail) 

## Data import

We start importing the raw table of counts.

```{r start}
library(SummarizedExperiment)
# MARINA!!:
# Recorda marina que aquí ho tens en un altre directori: file.path("data", 
thca <- readRDS("seTHCA.rds") 
thca
```

Explore the column (phenotypic) data, which in this case corresponds to clinical
variables, and their corresponding metadata.

```{r explore1}
dim(colData(thca))
col.data <- colData(thca)
col.data[1:5, 1:5]

col.data.meta <- mcols(colData(thca), use.names=TRUE)
col.data.meta
```

Now, explore the row (feature) data.

```{r explore2}
row.ranges <- rowRanges(thca)
row.ranges
```

Looking deeper into col.data with:

```{r explore.col.data}
col.data[1:5, 30:35]
```

We can observed that where some data not available indicated differently (NA, [Not Available]...) so we decided to study which variables have more information. To do so we created two functions, one (`na.replace`) to change those vales into the standarized `NA` nomenclature, and `filter.info` to quantify how many of each variable is not `NA`.

```{r functions}

na.replace <- function(x){
    # Remove the unwanted factors
    lev <- levels(x)
    lev <- lev[!(lev %in% "[Not Available]")]
    lev <- lev[!(lev %in% "[Unknown]")]
    lev <- lev[!(lev %in% "[Not Applicable]")]
    lev <- lev[!(lev %in% "[Not Available]|[Not Available]|[Not Available]")]
    lev <- lev[!(lev %in% "[Not Evaluated]")]

    x <- factor(x, levels=lev)
}

filter.info <- function(x){
    # Function to filter the NA, [Not Available], [Not Applicable] and [Unknown]
    # Return the proportion of information on x
    nas <- sum(is.na(x))
    return(1 - (nas/length(x)))
}
```

We applied this functions to the `col.data` and we visualized it:

```{r col.data.analysis}
meta.info <- as.data.frame(lapply(col.data, na.replace))
variable.info <- sapply(meta.info, filter.info)

# Plotting the histogram of the information
hist(variable.info, 
     main = "Variables completness", xlab = "% of not NA of each variable")
# Seeing the most informative to set a threshold,
# frequency are the number of columns with such % of information
hist(variable.info, xlim = c(0.3, 1), ylim = c(0, 35), 
     main = "Variables completness", xlab = "% of not NA of each variable")

# Representing the information by column vs total information
relative.info <- variable.info[order(variable.info)]/sum(variable.info)
plot(relative.info, main="Information brought by column")
```

As we can see in many  variables with just `NA` and very few with other values. 
We decided a threshold of 60%:

```{r select.filtered}
filtered <- meta.info[, variable.info  > 0.6]
meta.info.summary2 <- col.data.meta[variable.info  > 0.6,]
```

To explore the data we first create an object to explore with `ggplot`:
```{r ggplot.config}
library("ggplot2")
fplot <- ggplot(as.data.frame(filtered))

## ggplot options for axes and background color
# Options of the labels
l <- theme(axis.text.x=element_text(angle = -90, hjust = 0, vjust = 1))
# Removing the background
b <-  theme(axis.line = element_line(colour = "black"),
            panel.grid.major.x = element_blank(),
            panel.grid.major.y = element_line(colour = "grey", size = 0.5, linetype = 2),
            panel.grid.minor.y = element_line(colour = "grey", size = 0.25, linetype = 3),
            panel.border = element_blank(),
            panel.background = element_blank())
```

And we plot some relationships for some significant variables:

```{r plots, fig.cap = fig$cap("Figure S1","Exploring the col.data")}
fplot + geom_bar(aes(type, fill = gender)) + b
fplot + geom_bar(aes(type, fill = tumor_status)) + b
fplot + facet_wrap(~ gender) + geom_bar(aes(type, fill = ethnicity)) + b
fplot + facet_wrap(~ ethnicity) + geom_bar(aes(race, fill = gender)) + b + l
fplot + geom_bar(aes(x=gender, fill = race)) + b + l
fplot + facet_wrap(~type)+geom_bar(aes(tumor_focality, fill = gender)) + b + l
fplot + geom_bar(aes(histologic_diagnosis, fill = gender))+b+l
fplot + geom_bar(aes(age_at_diagnosis, fill = histologic_diagnosis)) + b + l
```

We can see in `r fig$ref("Figure S1")` the data has some patterns, there are more females than males, and much more tumoral than normal samples.

We decide to perform the analysis on the white population not hispanic or latino, whose tumoral sample correspond to the most common cancer in thyroids the Thyroid Papillary Carcinoma. To have more inshight on the disease we want to have just paired samples, that is, samples from the same participant. So we filter the data accordingly:

```{r subset}
 #Paired data
paired <- intersect(thca[, thca$type == 'tumor']$bcr_patient_barcode, thca[, thca$type =='normal']$bcr_patient_barcode)
paired_mask <- thca$bcr_patient_barcode %in% paired

filtered_filt <- filtered[paired_mask, ]

# Imposing the selected conditions
tumor_names <- row.names(subset(filtered_filt, type == "tumor" &
                                    race == "WHITE" &
    histologic_diagnosis == "Thyroid Papillary Carcinoma - Classical/usual" &
        ethnicity == "NOT HISPANIC OR LATINO" ))

# Extracting the participants identifiers
participants <- unlist(lapply(tumor_names, substr, start = 9, stop = 12))
participants <- participants[participants != ""]

check <- function(x, checklist){
    # Returning name of the sample just if the name is the same as in checklist
    a <- substr(x, 9, 12)
    if(a %in% checklist){
        return(x)
    }
}

# extracting sample names of tumor and normal data.
sample_names <- unlist(lapply(row.names(filtered_filt), check, checklist = participants))
```

We explore again the variables for these subset:
```{r subset.explore}
meta.filtered.subset <- filtered_filt[row.names(filtered_filt) %in% sample_names, ]
mplot <- ggplot(meta.filtered.subset)
mplot + geom_bar(aes(type, fill = gender)) + b
mplot + geom_bar(aes(type, fill = tumor_status)) + b
mplot + facet_wrap(~ gender) + geom_bar(aes(type, fill = ethnicity)) + b
mplot + facet_wrap(~ ethnicity) + geom_bar(aes(race, fill = gender)) + b + l
mplot + geom_bar(aes(x=gender, fill = race)) + b + l
mplot + facet_wrap(~type)+geom_bar(aes(tumor_focality, fill = gender)) + b + l
mplot + geom_bar(aes(histologic_diagnosis, fill = gender))+b+l
mplot + geom_bar(aes(age_at_diagnosis, fill = histologic_diagnosis)) + b + l
```


To perform quality assessment and normalization we need first to load the
[edgeR](http://bioconductor.org/packages/edgeR) R/Bioconductor package and
create a `DGEList' object.

```{r}
library(edgeR)
thca_expr <- assays(thca)$counts
thca.counts.filtered <- thca_expr[, colnames(thca_expr) %in% sample_names]
# Normalization just with the selected samples
dge.subset <- DGEList(counts=thca.counts.filtered, genes=mcols(thca))
dge <- DGEList(counts=thca_expr, genes=mcols(thca))
```

Now calculate $\log_2$ CPM values of expression and put them as an additional
assay element to ease their manipulation.

```{r}
# Using the normalized value changing the pior count to 3
assays(thca)$logCPM <- cpm(dge, log=TRUE, prior.count=3) 
assays(thca)$logCPM[1:5, 1:5]
logCPM <- assays(thca)$logCPM

# Just the subset
thca.counts.filtered$logCPM <- cpm(dge.subset, log=TRUE, prior.count=3)
thca.counts.filtered$logCPM[1:5, 1:5]
logCPM <- thca.counts.filtered$logCPM
```

## Quality assessment and normalization

### Library sizes

Let's examine the library sizes in terms of total number of sequence read counts
per sample. Figure S1 below shows library sizes per sample in increasing order.

<!---
you can control the height and width in pixels of the figure with 'out.height' and 'out.width'
--->

```{r libsizes, echo=FALSE, out.width="600px", fig.cap="Figure S1: Library sizes in increasing order."}
ord <- order(dge$sample$lib.size/1e6)
barplot(dge$sample$lib.size[ord]/1e6, las=1, ylab="Millions of reads",
        xlab="Samples", col=c("blue", "red")[(thca$type[ord] == "tumor") + 1])
legend("topleft", c("tumor", "normal"), fill=c("red", "blue"), inset=0.01)

ord.subset <- order(dge.subset$sample$lib.size/1e6)
barplot(dge.subset$sample$lib.size[ord.subset]/1e6, las=1, ylab="Millions of reads",
        xlab="Samples", col=c("blue", "red")[(thca.filtered$type[ord.subset] == "tumor") + 1])
legend("topleft", c("tumor", "normal"), fill=c("red", "blue"), inset=0.01)
```